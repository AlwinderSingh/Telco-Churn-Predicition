# Telco-Churn-Predicition
# 
### Problem Statement: [Telco Churn Prediction](https://www.kaggle.com/blastchar/telco-customer-churn)
### Table of Contents:
|Sno|Step  |
|--|--|
| 1 | **Importing Libraries** |
| 2 | **Data Preprocessing and Exploratory Data Analysis** |
|  | 2.1: Importing Dataset |
|  | 2.2: Handling Missing Values |
|  | 2.3: Statistical Analysis |
|  | 2.4: Binning/Discretization |
|  | 2.5: Outlier Treatment |
|  | 2.6: Exploratory Data Analysis |
|  | 2.7: Splitting Dependent/Independent Variables |
|  | 2.8: Importing Dataset |
|  | 2.9: Label Encoding |
|  | 2.10: One Hot Encoding |
|  | 2.11: Class Balancing |
|  | 2.12: Normalization |
|  | 2.13: Train Test Split |
| 3|  **Classification Using Deep Learning ( Artificial Neural Networks)**|
|  | 3.1: Initializing the ANN |
|  | 3.2: Adding the Input Layer and the Hidden Layers |
|  | 3.3: Adding the Output Layer |
|  | 3.4: Compiling the ANN |
|  | 3.5: Training the ANN |
|  | 3.6: Predicting the Reults |
|  | 3.7: Evaluating model Performance |
| 4|  **Machine Learning Models**|
|  | 4.1: Gaussian Naive Bayes |
|  | 4.2: K Nearest Neigbors |
|  | 4.3: Logistic Regression |
|  | 4.4: Decision Tree Classifier |
|  | 4.5: Random Forest Classifier |
|  | 4.6: Ada Boosting Classifier |
|  | 4.7: Gradient Boosting Classifier |
|  | 4.8: XGB Classifier |
### Table of Comparison:
|Sno|Model|Accuracy|Precision for Yes | Recall for Yes |F1 score for Yes |  
|--|--|--|--|--|--|
|  | 1: Artificial Neural Networks |0.93|0.94|0.93|0.94|
|  | 2: Gaussian Naive Bayes |0.89|0.94|0.87|0.90|
|  | 3: K Nearest Neigbors |0.90|0.97|0.87|0.92|
|  | 4: Logistic Regression |0.91|0.92|0.92|0.92|
|  | 5: Decision Tree Classifier |0.93|0.95|0.93|0.94|
|  | 6: Random Forest Classifier |0.93|0.96|0.93|0.94|
|  | 7: Ada Boosting Classifier |0.95|0.96|0.94|0.95|
|  | 8: Gradient Boosting Classifier |0.96|0.96|0.96|0.96|
|  | 9: XGB Classifier |0.96|0.97|0.96|0.97|
